{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aniketSanyal/OverfittingInRML/blob/main/rml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "v1H4zuTLV0vj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "nKOB0WyqV-0d"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Models for CIFAR10 and MNIST"
      ],
      "metadata": {
        "id": "BLoBEu83WCAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CIFAR10_CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CIFAR10_CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.pool(self.conv1(x)))\n",
        "        x = F.relu(self.pool(self.conv2(x)))\n",
        "        x = F.relu(self.pool(self.conv3(x)))\n",
        "        x = x.view(-1, 128 * 4 * 4)  # Flatten the tensor\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "class MNIST_CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNIST_CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 256)\n",
        "        self.fc2 = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.pool(self.conv1(x)))\n",
        "        x = F.relu(self.pool(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 7 * 7)  # Flatten the tensor\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "-tlhjs7eWDKz"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define FGSM and PGD Attack Functions"
      ],
      "metadata": {
        "id": "sPkQ0-fBWGdP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fgsm_attack(image, epsilon, data_grad):\n",
        "    # Collect the element-wise sign of the data gradient\n",
        "    sign_data_grad = data_grad.sign()\n",
        "    # Create the perturbed image by adjusting each pixel of the input image\n",
        "    perturbed_image = image + epsilon * sign_data_grad\n",
        "    # Adding clipping to maintain [0,1] range\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "    return perturbed_image\n",
        "\n",
        "def pgd_attack(model, image, label, epsilon, alpha, iters, device):\n",
        "    # Initialize perturbation as zero\n",
        "    perturbation = torch.zeros_like(image).to(device)\n",
        "    perturbation.requires_grad = True\n",
        "\n",
        "    for _ in range(iters):\n",
        "        outputs = model(image + perturbation)\n",
        "        loss = F.cross_entropy(outputs, label)\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # Update the perturbation\n",
        "        perturbation.data += alpha * perturbation.grad.data.sign()\n",
        "        perturbation.data = torch.clamp(perturbation.data, -epsilon, epsilon)\n",
        "\n",
        "    # Apply the perturbation and clip the result\n",
        "    perturbed_image = torch.clamp(image + perturbation, 0, 1)\n",
        "    return perturbed_image\n"
      ],
      "metadata": {
        "id": "rhTWtmFtWJyk"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data for Both Datasets"
      ],
      "metadata": {
        "id": "xXjLAL2SWLr1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformations for CIFAR10\n",
        "transform_cifar = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalizing for CIFAR10\n",
        "])\n",
        "\n",
        "# Transformations for MNIST\n",
        "transform_mnist = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalizing for MNIST\n",
        "])\n",
        "\n",
        "# CIFAR10\n",
        "cifar_train = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_cifar)\n",
        "cifar_test = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_cifar)\n",
        "\n",
        "# MNIST\n",
        "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform_mnist)\n",
        "mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=transform_mnist)\n",
        "\n",
        "# Data loaders with batch processing\n",
        "batch_size = 64  # You can adjust the batch size\n",
        "\n",
        "cifar_train_loader = DataLoader(cifar_train, batch_size=batch_size, shuffle=True)\n",
        "cifar_test_loader = DataLoader(cifar_test, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "mnist_train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
        "mnist_test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWGBPHd8WNy4",
        "outputId": "0a772753-3575-47c0-c57b-e2fb187c7cb8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Testing Functions"
      ],
      "metadata": {
        "id": "W4ixonIQWQ9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()  # Set the model to training mode\n",
        "    total_loss = 0\n",
        "    correct = 0  # Initialize correct predictions counter\n",
        "    total = 0  # Initialize total predictions counter\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        total += target.size(0)  # Accumulate total\n",
        "\n",
        "        optimizer.zero_grad()  # Zero the gradients\n",
        "        output = model(data)  # Forward pass\n",
        "        loss = F.cross_entropy(output, target)  # Compute loss\n",
        "        loss.backward()  # Backward pass\n",
        "        optimizer.step()  # Update weights\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        pred = output.argmax(dim=1)  # Get the index of the max log-probability\n",
        "        correct += pred.eq(target).sum().item()  # Accumulate correct predictions\n",
        "\n",
        "    average_loss = total_loss / len(train_loader.dataset)\n",
        "    accuracy = 100 * correct / total  # Calculate accuracy\n",
        "    return average_loss, accuracy\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():  # No need to track gradients for testing\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            total += target.size(0)\n",
        "\n",
        "            output = model(data)\n",
        "            test_loss += F.cross_entropy(output, target, reduction='sum').item()  # Sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    accuracy = 100 * correct / total  # Calculate accuracy\n",
        "    return test_loss, accuracy\n",
        "\n",
        "def train_adversarial(model, device, train_loader, optimizer, epoch, attack, epsilon, alpha=None, iters=None):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0  # Initialize correct predictions counter\n",
        "    total = 0  # Initialize total predictions counter\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        total += target.size(0)  # Accumulate total predictions\n",
        "\n",
        "        # Generate adversarial examples\n",
        "        if attack == fgsm_attack:\n",
        "            data.requires_grad = True\n",
        "            output = model(data)\n",
        "            loss = F.cross_entropy(output, target)\n",
        "            model.zero_grad()\n",
        "            loss.backward()\n",
        "            data_grad = data.grad.data\n",
        "            adversarial_data = fgsm_attack(data, epsilon, data_grad)\n",
        "        elif attack == pgd_attack and alpha is not None and iters is not None:\n",
        "            adversarial_data = pgd_attack(model, data, target, epsilon, alpha, iters, device)\n",
        "        else:\n",
        "            raise ValueError(\"Invalid attack method or missing parameters for PGD\")\n",
        "\n",
        "        # Training step with adversarial examples\n",
        "        optimizer.zero_grad()\n",
        "        output = model(adversarial_data)\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        pred = output.argmax(dim=1)  # Get the index of the max log-probability\n",
        "        correct += pred.eq(target).sum().item()  # Accumulate correct predictions\n",
        "\n",
        "    average_loss = total_loss / len(train_loader.dataset)\n",
        "    accuracy = 100 * correct / total  # Calculate accuracy\n",
        "    return average_loss, accuracy\n",
        "\n",
        "def test_adversarial(model, device, test_loader, attack, epsilon, alpha=None, iters=None):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for data, target in test_loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        total += target.size(0)\n",
        "\n",
        "        # Set requires_grad to True for attack generation\n",
        "        data.requires_grad = True\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(data)\n",
        "        loss = F.cross_entropy(output, target)\n",
        "\n",
        "        # If attack is FGSM, generate adversarial example\n",
        "        if attack == fgsm_attack:\n",
        "            model.zero_grad()\n",
        "            loss.backward()\n",
        "            data_grad = data.grad\n",
        "            adversarial_data = fgsm_attack(data, epsilon, data_grad)\n",
        "        elif attack == pgd_attack and alpha is not None and iters is not None:\n",
        "            adversarial_data = pgd_attack(model, data, target, epsilon, alpha, iters, device)\n",
        "        else:\n",
        "            raise ValueError(\"Invalid attack method or missing parameters for PGD\")\n",
        "\n",
        "        # Evaluate on adversarial examples\n",
        "        output = model(adversarial_data)\n",
        "        test_loss += F.cross_entropy(output, target, reduction='sum').item()  # Sum up batch loss\n",
        "        pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max log-probability\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    accuracy = 100. * correct / total  # Calculate accuracy\n",
        "    return test_loss, accuracy\n"
      ],
      "metadata": {
        "id": "859HuzEnWTxG"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Testing with Adversarial Attacks"
      ],
      "metadata": {
        "id": "EXOZ67K9WV1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize CIFAR10 and MNIST models\n",
        "model_cifar = CIFAR10_CNN().to(device)\n",
        "model_mnist = MNIST_CNN().to(device)\n",
        "\n",
        "# Define optimizers for each model\n",
        "optimizer_cifar = torch.optim.Adam(model_cifar.parameters(), lr=0.001)\n",
        "optimizer_mnist = torch.optim.Adam(model_mnist.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10  # Define the number of epochs\n",
        "# Set parameters for attacks\n",
        "epsilon = 0.1  # Perturbation magnitude for FGSM\n",
        "alpha = 0.01   # Step size for PGD\n",
        "iters = 40     # Number of iterations for PGD\n",
        "\n",
        "train_accuracies_cifar, test_accuracies_cifar = [], []\n",
        "train_accuracies_mnist, test_accuracies_mnist = [], []\n",
        "train_accuracies_cifar_adv, test_accuracies_cifar_adv = [], []\n",
        "train_accuracies_mnist_adv, test_accuracies_mnist_adv = [], []\n",
        "train_accuracies_cifar_pgd, test_accuracies_cifar_pgd = [], []\n",
        "train_accuracies_mnist_pgd, test_accuracies_mnist_pgd = [], []\n",
        "train_losses_cifar, test_losses_cifar = [], []\n",
        "train_losses_mnist, test_losses_mnist = [], []\n",
        "train_losses_cifar_adv, test_losses_cifar_adv = [], []\n",
        "train_losses_mnist_adv, test_losses_mnist_adv = [], []\n",
        "train_losses_cifar_pgd, test_losses_cifar_pgd = [], []\n",
        "train_losses_mnist_pgd, test_losses_mnist_pgd = [], []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # CIFAR10: 原始数据训练\n",
        "    train_loss_cifar, train_accuracy_cifar = train(model_cifar, device, cifar_train_loader, optimizer_cifar, epoch)\n",
        "    train_losses_cifar.append(train_loss_cifar)\n",
        "    train_accuracies_cifar.append(train_accuracy_cifar)\n",
        "\n",
        "    # CIFAR10: FGSM对抗性训练\n",
        "    train_loss_cifar_adv, train_accuracy_cifar_adv = train_adversarial(model_cifar, device, cifar_train_loader, optimizer_cifar, epoch, fgsm_attack, epsilon)\n",
        "    train_losses_cifar_adv.append(train_loss_cifar_adv)\n",
        "    train_accuracies_cifar_adv.append(train_accuracy_cifar_adv)\n",
        "\n",
        "    # CIFAR10: PGD对抗性训练\n",
        "    train_loss_cifar_pgd, train_accuracy_cifar_pgd = train_adversarial(model_cifar, device, cifar_train_loader, optimizer_cifar, epoch, pgd_attack, epsilon, alpha, iters)\n",
        "    train_losses_cifar_pgd.append(train_loss_cifar_pgd)\n",
        "    train_accuracies_cifar_pgd.append(train_accuracy_cifar_pgd)\n",
        "\n",
        "    # MNIST: 原始数据训练\n",
        "    train_loss_mnist, train_accuracy_mnist = train(model_mnist, device, mnist_train_loader, optimizer_mnist, epoch)\n",
        "    train_losses_mnist.append(train_loss_mnist)\n",
        "    train_accuracies_mnist.append(train_accuracy_mnist)\n",
        "\n",
        "    # MNIST: FGSM对抗性训练\n",
        "    train_loss_mnist_adv, train_accuracy_mnist_adv = train_adversarial(model_mnist, device, mnist_train_loader, optimizer_mnist, epoch, fgsm_attack, epsilon)\n",
        "    train_losses_mnist_adv.append(train_loss_mnist_adv)\n",
        "    train_accuracies_mnist_adv.append(train_accuracy_mnist_adv)\n",
        "\n",
        "    # MNIST: PGD对抗性训练\n",
        "    train_loss_mnist_pgd, train_accuracy_mnist_pgd = train_adversarial(model_mnist, device, mnist_train_loader, optimizer_mnist, epoch, pgd_attack, epsilon, alpha, iters)\n",
        "    train_losses_mnist_pgd.append(train_loss_mnist_pgd)\n",
        "    train_accuracies_mnist_pgd.append(train_accuracy_mnist_pgd)\n",
        "\n",
        "    # 在每个epoch结束后对干净数据进行测试\n",
        "    test_loss_cifar, test_accuracy_cifar = test(model_cifar, device, cifar_test_loader)\n",
        "    test_losses_cifar.append(test_loss_cifar)\n",
        "    test_accuracies_cifar.append(test_accuracy_cifar)\n",
        "\n",
        "    test_loss_mnist, test_accuracy_mnist = test(model_mnist, device, mnist_test_loader)\n",
        "    test_losses_mnist.append(test_loss_mnist)\n",
        "    test_accuracies_mnist.append(test_accuracy_mnist)\n",
        "\n",
        "    # 在每个epoch结束后对经过FGSM攻击的数据进行测试\n",
        "    test_loss_cifar_adv, test_accuracy_cifar_adv = test_adversarial(model_cifar, device, cifar_test_loader, fgsm_attack, epsilon)\n",
        "    test_losses_cifar_adv.append(test_loss_cifar_adv)\n",
        "    test_accuracies_cifar_adv.append(test_accuracy_cifar_adv)\n",
        "\n",
        "    test_loss_mnist_adv, test_accuracy_mnist_adv = test_adversarial(model_mnist, device, mnist_test_loader, fgsm_attack, epsilon)\n",
        "    test_losses_mnist_adv.append(test_loss_mnist_adv)\n",
        "    test_accuracies_mnist_adv.append(test_accuracy_mnist_adv)\n",
        "\n",
        "    # 在每个epoch结束后对经过PGD攻击的数据进行测试\n",
        "    test_loss_cifar_pgd, test_accuracy_cifar_pgd = test_adversarial(model_cifar, device, cifar_test_loader, pgd_attack, epsilon, alpha, iters)\n",
        "    test_losses_cifar_pgd.append(test_loss_cifar_pgd)\n",
        "    test_accuracies_cifar_pgd.append(test_accuracy_cifar_pgd)\n",
        "\n",
        "    test_loss_mnist_pgd, test_accuracy_mnist_pgd = test_adversarial(model_mnist, device, mnist_test_loader, pgd_attack, epsilon, alpha, iters)\n",
        "    test_losses_mnist_pgd.append(test_loss_mnist_pgd)\n",
        "    test_accuracies_mnist_pgd.append(test_accuracy_mnist_pgd)\n",
        "\n",
        "    # 打印信息\n",
        "    print(f'Epoch {epoch}:')\n",
        "    print(f'CIFAR10 - Clean Train Loss: {train_loss_cifar:.4f}, Accuracy: {train_accuracy_cifar:.2f}%')\n",
        "    print(f'CIFAR10 - FGSM Train Loss: {train_loss_cifar_adv:.4f}, Accuracy: {train_accuracy_cifar_adv:.2f}%')\n",
        "    print(f'CIFAR10 - PGD Train Loss: {train_loss_cifar_pgd:.4f}, Accuracy: {train_accuracy_cifar_pgd:.2f}%')\n",
        "    print(f'MNIST - Clean Train Loss: {train_loss_mnist:.4f}, Accuracy: {train_accuracy_mnist:.2f}%')\n",
        "    print(f'MNIST - FGSM Train Loss: {train_loss_mnist_adv:.4f}, Accuracy: {train_accuracy_mnist_adv:.2f}%')\n",
        "    print(f'MNIST - PGD Train Loss: {train_loss_mnist_pgd:.4f}, Accuracy: {train_accuracy_mnist_pgd:.2f}%')\n",
        "    print(f'CIFAR10 - Clean Test Loss: {test_loss_cifar:.4f}, Accuracy: {test_accuracy_cifar:.2f}%')\n",
        "    print(f'CIFAR10 - FGSM Test Loss: {test_loss_cifar_adv:.4f}, Accuracy: {test_accuracy_cifar_adv:.2f}%')\n",
        "    print(f'CIFAR10 - PGD Test Loss: {test_loss_cifar_pgd:.4f}, Accuracy: {test_accuracy_cifar_pgd:.2f}%')\n",
        "    print(f'MNIST - Clean Test Loss: {test_loss_mnist:.4f}, Accuracy: {test_accuracy_mnist:.2f}%')\n",
        "    print(f'MNIST - FGSM Test Loss: {test_loss_mnist_adv:.4f}, Accuracy: {test_accuracy_mnist_adv:.2f}%')\n",
        "    print(f'MNIST - PGD Test Loss: {test_loss_mnist_pgd:.4f}, Accuracy: {test_accuracy_mnist_pgd:.2f}%')\n",
        "    print('-' * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FuHfkpHWX0E",
        "outputId": "5990fd52-14e2-4496-fa11-8c00e209c0be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0:\n",
            "CIFAR10 - Clean Train Loss: 0.0212, Accuracy: 51.09%\n",
            "CIFAR10 - FGSM Train Loss: 0.0302, Accuracy: 28.48%\n",
            "CIFAR10 - PGD Train Loss: 0.0276, Accuracy: 36.16%\n",
            "MNIST - Clean Train Loss: 0.0021, Accuracy: 95.71%\n",
            "MNIST - FGSM Train Loss: 0.0016, Accuracy: 96.73%\n",
            "MNIST - PGD Train Loss: 0.0009, Accuracy: 98.13%\n",
            "CIFAR10 - Clean Test Loss: 3.5840, Accuracy: 33.40%\n",
            "CIFAR10 - FGSM Test Loss: 1.6773, Accuracy: 39.65%\n",
            "CIFAR10 - PGD Test Loss: 1.6814, Accuracy: 39.60%\n",
            "MNIST - Clean Test Loss: 0.0366, Accuracy: 98.88%\n",
            "MNIST - FGSM Test Loss: 0.0573, Accuracy: 98.03%\n",
            "MNIST - PGD Test Loss: 0.0576, Accuracy: 98.02%\n",
            "--------------------------------------------------\n",
            "Epoch 1:\n",
            "CIFAR10 - Clean Train Loss: 0.0156, Accuracy: 64.74%\n",
            "CIFAR10 - FGSM Train Loss: 0.0268, Accuracy: 36.61%\n",
            "CIFAR10 - PGD Train Loss: 0.0253, Accuracy: 41.69%\n",
            "MNIST - Clean Train Loss: 0.0004, Accuracy: 99.26%\n",
            "MNIST - FGSM Train Loss: 0.0006, Accuracy: 98.64%\n",
            "MNIST - PGD Train Loss: 0.0004, Accuracy: 99.15%\n",
            "CIFAR10 - Clean Test Loss: 2.6137, Accuracy: 39.99%\n",
            "CIFAR10 - FGSM Test Loss: 1.5860, Accuracy: 43.02%\n",
            "CIFAR10 - PGD Test Loss: 1.5977, Accuracy: 43.07%\n",
            "MNIST - Clean Test Loss: 0.0260, Accuracy: 99.19%\n",
            "MNIST - FGSM Test Loss: 0.0510, Accuracy: 98.42%\n",
            "MNIST - PGD Test Loss: 0.0515, Accuracy: 98.38%\n",
            "--------------------------------------------------\n",
            "Epoch 2:\n",
            "CIFAR10 - Clean Train Loss: 0.0123, Accuracy: 72.38%\n",
            "CIFAR10 - FGSM Train Loss: 0.0245, Accuracy: 42.21%\n",
            "CIFAR10 - PGD Train Loss: 0.0227, Accuracy: 47.80%\n",
            "MNIST - Clean Train Loss: 0.0002, Accuracy: 99.57%\n",
            "MNIST - FGSM Train Loss: 0.0004, Accuracy: 99.20%\n",
            "MNIST - PGD Train Loss: 0.0002, Accuracy: 99.49%\n",
            "CIFAR10 - Clean Test Loss: 2.3575, Accuracy: 43.78%\n",
            "CIFAR10 - FGSM Test Loss: 1.5287, Accuracy: 45.42%\n",
            "CIFAR10 - PGD Test Loss: 1.5408, Accuracy: 45.62%\n",
            "MNIST - Clean Test Loss: 0.0484, Accuracy: 99.12%\n",
            "MNIST - FGSM Test Loss: 0.0660, Accuracy: 98.36%\n",
            "MNIST - PGD Test Loss: 0.0669, Accuracy: 98.34%\n",
            "--------------------------------------------------\n",
            "Epoch 3:\n",
            "CIFAR10 - Clean Train Loss: 0.0101, Accuracy: 77.29%\n",
            "CIFAR10 - FGSM Train Loss: 0.0218, Accuracy: 48.91%\n",
            "CIFAR10 - PGD Train Loss: 0.0200, Accuracy: 54.04%\n",
            "MNIST - Clean Train Loss: 0.0001, Accuracy: 99.76%\n",
            "MNIST - FGSM Train Loss: 0.0002, Accuracy: 99.59%\n",
            "MNIST - PGD Train Loss: 0.0001, Accuracy: 99.70%\n",
            "CIFAR10 - Clean Test Loss: 2.2569, Accuracy: 45.70%\n",
            "CIFAR10 - FGSM Test Loss: 1.5405, Accuracy: 46.13%\n",
            "CIFAR10 - PGD Test Loss: 1.5880, Accuracy: 45.43%\n",
            "MNIST - Clean Test Loss: 0.0369, Accuracy: 99.27%\n",
            "MNIST - FGSM Test Loss: 0.0604, Accuracy: 98.46%\n",
            "MNIST - PGD Test Loss: 0.0611, Accuracy: 98.37%\n",
            "--------------------------------------------------\n",
            "Epoch 4:\n",
            "CIFAR10 - Clean Train Loss: 0.0082, Accuracy: 81.32%\n",
            "CIFAR10 - FGSM Train Loss: 0.0199, Accuracy: 53.02%\n",
            "CIFAR10 - PGD Train Loss: 0.0177, Accuracy: 59.17%\n",
            "MNIST - Clean Train Loss: 0.0001, Accuracy: 99.78%\n",
            "MNIST - FGSM Train Loss: 0.0002, Accuracy: 99.66%\n",
            "MNIST - PGD Train Loss: 0.0001, Accuracy: 99.86%\n",
            "CIFAR10 - Clean Test Loss: 1.9696, Accuracy: 49.21%\n",
            "CIFAR10 - FGSM Test Loss: 1.5632, Accuracy: 47.16%\n",
            "CIFAR10 - PGD Test Loss: 1.6257, Accuracy: 46.39%\n",
            "MNIST - Clean Test Loss: 0.0486, Accuracy: 99.16%\n",
            "MNIST - FGSM Test Loss: 0.0930, Accuracy: 98.17%\n",
            "MNIST - PGD Test Loss: 0.0943, Accuracy: 98.14%\n",
            "--------------------------------------------------\n",
            "Epoch 5:\n",
            "CIFAR10 - Clean Train Loss: 0.0065, Accuracy: 85.28%\n",
            "CIFAR10 - FGSM Train Loss: 0.0181, Accuracy: 56.84%\n",
            "CIFAR10 - PGD Train Loss: 0.0158, Accuracy: 63.63%\n",
            "MNIST - Clean Train Loss: 0.0001, Accuracy: 99.77%\n",
            "MNIST - FGSM Train Loss: 0.0001, Accuracy: 99.68%\n",
            "MNIST - PGD Train Loss: 0.0001, Accuracy: 99.84%\n",
            "CIFAR10 - Clean Test Loss: 1.9713, Accuracy: 52.91%\n",
            "CIFAR10 - FGSM Test Loss: 1.7156, Accuracy: 45.54%\n",
            "CIFAR10 - PGD Test Loss: 1.7840, Accuracy: 44.52%\n",
            "MNIST - Clean Test Loss: 0.0411, Accuracy: 99.30%\n",
            "MNIST - FGSM Test Loss: 0.0762, Accuracy: 98.45%\n",
            "MNIST - PGD Test Loss: 0.0782, Accuracy: 98.38%\n",
            "--------------------------------------------------\n",
            "Epoch 6:\n",
            "CIFAR10 - Clean Train Loss: 0.0051, Accuracy: 88.48%\n",
            "CIFAR10 - FGSM Train Loss: 0.0159, Accuracy: 62.34%\n",
            "CIFAR10 - PGD Train Loss: 0.0137, Accuracy: 68.49%\n",
            "MNIST - Clean Train Loss: 0.0001, Accuracy: 99.83%\n",
            "MNIST - FGSM Train Loss: 0.0001, Accuracy: 99.75%\n",
            "MNIST - PGD Train Loss: 0.0001, Accuracy: 99.86%\n",
            "CIFAR10 - Clean Test Loss: 2.0258, Accuracy: 52.72%\n",
            "CIFAR10 - FGSM Test Loss: 1.8510, Accuracy: 45.87%\n",
            "CIFAR10 - PGD Test Loss: 1.9594, Accuracy: 45.11%\n",
            "MNIST - Clean Test Loss: 0.0498, Accuracy: 99.19%\n",
            "MNIST - FGSM Test Loss: 0.0779, Accuracy: 98.45%\n",
            "MNIST - PGD Test Loss: 0.0777, Accuracy: 98.49%\n",
            "--------------------------------------------------\n",
            "Epoch 7:\n",
            "CIFAR10 - Clean Train Loss: 0.0041, Accuracy: 90.63%\n",
            "CIFAR10 - FGSM Train Loss: 0.0146, Accuracy: 65.07%\n",
            "CIFAR10 - PGD Train Loss: 0.0125, Accuracy: 71.15%\n",
            "MNIST - Clean Train Loss: 0.0001, Accuracy: 99.84%\n",
            "MNIST - FGSM Train Loss: 0.0001, Accuracy: 99.79%\n",
            "MNIST - PGD Train Loss: 0.0001, Accuracy: 99.87%\n",
            "CIFAR10 - Clean Test Loss: 1.8140, Accuracy: 55.00%\n",
            "CIFAR10 - FGSM Test Loss: 1.9918, Accuracy: 44.08%\n",
            "CIFAR10 - PGD Test Loss: 2.1493, Accuracy: 42.62%\n",
            "MNIST - Clean Test Loss: 0.0662, Accuracy: 99.16%\n",
            "MNIST - FGSM Test Loss: 0.0855, Accuracy: 98.46%\n",
            "MNIST - PGD Test Loss: 0.0859, Accuracy: 98.42%\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizing the Results"
      ],
      "metadata": {
        "id": "1uAcAHaSWZYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_losses_cifar, label='Clean Training Loss')\n",
        "plt.plot(train_losses_cifar_adv, label='FGSM Training Loss')\n",
        "plt.plot(train_losses_cifar_pgd, label='PGD Training Loss')\n",
        "plt.title('CIFAR10 Training Loss Comparison')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_accuracies_cifar, label='Clean Training Accuracy')\n",
        "plt.plot(train_accuracies_cifar_adv, label='FGSM Training Accuracy')\n",
        "plt.plot(train_accuracies_cifar_pgd, label='PGD Training Accuracy')\n",
        "plt.title('CIFAR10 Training Accuracy Comparison')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(test_losses_cifar, label='Clean Test Loss')\n",
        "plt.plot(test_losses_cifar_adv, label='FGSM Test Loss')\n",
        "plt.plot(test_losses_cifar_pgd, label='PGD Test Loss')\n",
        "plt.title('CIFAR10 Test Loss Comparison')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(test_accuracies_cifar, label='Clean Test Accuracy')\n",
        "plt.plot(test_accuracies_cifar_adv, label='FGSM Test Accuracy')\n",
        "plt.plot(test_accuracies_cifar_pgd, label='PGD Test Accuracy')\n",
        "plt.title('CIFAR10 Test Accuracy Comparison')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_losses_mnist, label='Clean Training Loss')\n",
        "plt.plot(train_losses_mnist_adv, label='FGSM Training Loss')\n",
        "plt.plot(train_losses_mnist_pgd, label='PGD Training Loss')\n",
        "plt.title('MNIST Training Loss Comparison')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_accuracies_mnist, label='Clean Training Accuracy')\n",
        "plt.plot(train_accuracies_mnist_adv, label='FGSM Training Accuracy')\n",
        "plt.plot(train_accuracies_mnist_pgd, label='PGD Training Accuracy')\n",
        "plt.title('MNIST Training Accuracy Comparison')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(test_losses_mnist, label='Clean Test Loss')\n",
        "plt.plot(test_losses_mnist_adv, label='FGSM Test Loss')\n",
        "plt.plot(test_losses_mnist_pgd, label='PGD Test Loss')\n",
        "plt.title('MNIST Test Loss Comparison')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(test_accuracies_mnist, label='Clean Test Accuracy')\n",
        "plt.plot(test_accuracies_mnist_adv, label='FGSM Test Accuracy')\n",
        "plt.plot(test_accuracies_mnist_pgd, label='PGD Test Accuracy')\n",
        "plt.title('MNIST Test Accuracy Comparison')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PBEhEhuSWalj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}