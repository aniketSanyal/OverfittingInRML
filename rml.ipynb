{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aniketSanyal/OverfittingInRML/blob/main/rml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "v1H4zuTLV0vj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "nKOB0WyqV-0d"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Models for CIFAR10 and MNIST"
      ],
      "metadata": {
        "id": "BLoBEu83WCAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CIFAR10_CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CIFAR10_CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.pool(self.conv1(x)))\n",
        "        x = F.relu(self.pool(self.conv2(x)))\n",
        "        x = F.relu(self.pool(self.conv3(x)))\n",
        "        x = x.view(-1, 128 * 4 * 4)  # Flatten the tensor\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "class MNIST_CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNIST_CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 256)\n",
        "        self.fc2 = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.pool(self.conv1(x)))\n",
        "        x = F.relu(self.pool(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 7 * 7)  # Flatten the tensor\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "-tlhjs7eWDKz"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define FGSM and PGD Attack Functions"
      ],
      "metadata": {
        "id": "sPkQ0-fBWGdP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fgsm_attack(image, epsilon, data_grad):\n",
        "    # Collect the element-wise sign of the data gradient\n",
        "    sign_data_grad = data_grad.sign()\n",
        "    # Create the perturbed image by adjusting each pixel of the input image\n",
        "    perturbed_image = image + epsilon * sign_data_grad\n",
        "    # Adding clipping to maintain [0,1] range\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "    return perturbed_image\n",
        "\n",
        "def pgd_attack(model, image, label, epsilon, alpha, iters, device):\n",
        "    # Initialize perturbation as zero\n",
        "    perturbation = torch.zeros_like(image).to(device)\n",
        "    perturbation.requires_grad = True\n",
        "\n",
        "    for _ in range(iters):\n",
        "        outputs = model(image + perturbation)\n",
        "        loss = F.cross_entropy(outputs, label)\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # Update the perturbation\n",
        "        perturbation.data += alpha * perturbation.grad.data.sign()\n",
        "        perturbation.data = torch.clamp(perturbation.data, -epsilon, epsilon)\n",
        "\n",
        "    # Apply the perturbation and clip the result\n",
        "    perturbed_image = torch.clamp(image + perturbation, 0, 1)\n",
        "    return perturbed_image\n"
      ],
      "metadata": {
        "id": "rhTWtmFtWJyk"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data for Both Datasets"
      ],
      "metadata": {
        "id": "xXjLAL2SWLr1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformations for CIFAR10\n",
        "transform_cifar = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalizing for CIFAR10\n",
        "])\n",
        "\n",
        "# Transformations for MNIST\n",
        "transform_mnist = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalizing for MNIST\n",
        "])\n",
        "\n",
        "# CIFAR10\n",
        "cifar_train = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_cifar)\n",
        "cifar_test = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_cifar)\n",
        "\n",
        "# MNIST\n",
        "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform_mnist)\n",
        "mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=transform_mnist)\n",
        "\n",
        "# Data loaders with batch processing\n",
        "batch_size = 64  # You can adjust the batch size\n",
        "\n",
        "cifar_train_loader = DataLoader(cifar_train, batch_size=batch_size, shuffle=True)\n",
        "cifar_test_loader = DataLoader(cifar_test, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "mnist_train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
        "mnist_test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWGBPHd8WNy4",
        "outputId": "51f97f00-edf1-4cfd-daa1-aa7b0796b7b5"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Testing Functions"
      ],
      "metadata": {
        "id": "W4ixonIQWQ9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()  # Set the model to training mode\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        optimizer.zero_grad()  # Zero the gradients\n",
        "        output = model(data)  # Forward pass\n",
        "        loss = F.cross_entropy(output, target)  # Compute loss\n",
        "        loss.backward()  # Backward pass\n",
        "        optimizer.step()  # Update weights\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        if batch_idx % 100 == 0:  # Print status every 100 batches\n",
        "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
        "\n",
        "    average_loss = total_loss / len(train_loader.dataset)\n",
        "    print(f'Training set: Average loss: {average_loss:.4f}')\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():  # No need to track gradients for testing\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.cross_entropy(output, target, reduction='sum').item()  # Sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    accuracy = 100. * correct / len(test_loader.dataset)\n",
        "\n",
        "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({accuracy:.0f}%)\\n')\n",
        "\n",
        "def train_adversarial(model, device, train_loader, optimizer, epoch, attack, epsilon=0.1, alpha=None, iters=None):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        # Generate adversarial examples\n",
        "        if attack == fgsm_attack:\n",
        "            data.requires_grad = True\n",
        "            output = model(data)\n",
        "            loss = F.cross_entropy(output, target)\n",
        "            model.zero_grad()\n",
        "            loss.backward()\n",
        "            data_grad = data.grad.data\n",
        "            adversarial_data = fgsm_attack(data, epsilon, data_grad)\n",
        "        elif attack == pgd_attack and alpha is not None and iters is not None:\n",
        "            adversarial_data = pgd_attack(model, data, target, epsilon, alpha, iters, device)\n",
        "        else:\n",
        "            raise ValueError(\"Invalid attack method or missing parameters for PGD\")\n",
        "\n",
        "        # Training step with adversarial examples\n",
        "        optimizer.zero_grad()\n",
        "        output = model(adversarial_data)\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
        "\n",
        "    average_loss = total_loss / len(train_loader.dataset)\n",
        "    print(f'Training set: Average loss: {average_loss:.4f}')\n",
        "\n",
        "def test_adversarial(model, device, test_loader, attack, epsilon=0.1, alpha=None, iters=None):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    for data, target in test_loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        # Set requires_grad attribute of tensor. Important for Attack\n",
        "        data.requires_grad = True\n",
        "\n",
        "        # Generate adversarial examples\n",
        "        if attack == fgsm_attack:\n",
        "            output = model(data)\n",
        "            loss = F.cross_entropy(output, target)\n",
        "            model.zero_grad()\n",
        "            loss.backward()\n",
        "            data_grad = data.grad.data\n",
        "            adversarial_data = fgsm_attack(data, epsilon, data_grad)\n",
        "        elif attack == pgd_attack and alpha is not None and iters is not None:\n",
        "            adversarial_data = pgd_attack(model, data, target, epsilon, alpha, iters, device)\n",
        "        else:\n",
        "            raise ValueError(\"Invalid attack method or missing parameters for PGD\")\n",
        "\n",
        "        # Evaluate on adversarial examples\n",
        "        output = model(adversarial_data)\n",
        "        test_loss += F.cross_entropy(output, target, reduction='sum').item()  # Sum up batch loss\n",
        "        pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max log-probability\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    print(f'\\nTest set (adversarial): Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({accuracy:.0f}%)\\n')\n"
      ],
      "metadata": {
        "id": "859HuzEnWTxG"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and Testing with Adversarial Attacks"
      ],
      "metadata": {
        "id": "EXOZ67K9WV1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize CIFAR10 and MNIST models\n",
        "model_cifar = CIFAR10_CNN().to(device)\n",
        "model_mnist = MNIST_CNN().to(device)\n",
        "\n",
        "# Define optimizers for each model\n",
        "optimizer_cifar = torch.optim.Adam(model_cifar.parameters(), lr=0.001)\n",
        "optimizer_mnist = torch.optim.Adam(model_mnist.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10  # Define the number of epochs\n",
        "# Set parameters for attacks\n",
        "epsilon = 0.1  # Perturbation magnitude for FGSM\n",
        "alpha = 0.01   # Step size for PGD\n",
        "iters = 40     # Number of iterations for PGD\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Training with original data\n",
        "    train(model_cifar, device, cifar_train_loader, optimizer_cifar, epoch)\n",
        "    train(model_mnist, device, mnist_train_loader, optimizer_mnist, epoch)\n",
        "\n",
        "    # Training with FGSM adversarial examples\n",
        "    train_adversarial(model_cifar, device, cifar_train_loader, optimizer_cifar, epoch, fgsm_attack, epsilon)\n",
        "    train_adversarial(model_mnist, device, mnist_train_loader, optimizer_mnist, epoch, fgsm_attack, epsilon)\n",
        "\n",
        "    # Training with PGD adversarial examples\n",
        "    train_adversarial(model_cifar, device, cifar_train_loader, optimizer_cifar, epoch, pgd_attack, epsilon, alpha, iters)\n",
        "    train_adversarial(model_mnist, device, mnist_train_loader, optimizer_mnist, epoch, pgd_attack, epsilon, alpha, iters)\n",
        "\n",
        "\n",
        "# Test on clean examples\n",
        "test(model_cifar, device, cifar_test_loader)\n",
        "test(model_mnist, device, mnist_test_loader)\n",
        "\n",
        "# Test on FGSM adversarial examples\n",
        "# Note: Similar to training, you'll need a test function that handles adversarial examples\n",
        "test_adversarial(model_cifar, device, cifar_test_loader, fgsm_attack)\n",
        "test_adversarial(model_mnist, device, mnist_test_loader, fgsm_attack)\n",
        "\n",
        "# Test on PGD adversarial examples\n",
        "test_adversarial(model_cifar, device, cifar_test_loader, pgd_attack)\n",
        "test_adversarial(model_mnist, device, mnist_test_loader, pgd_attack)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6FuHfkpHWX0E",
        "outputId": "f5218eef-a627-4080-c86a-e2e18cec7d2b"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 0 [0/50000 (0%)]\tLoss: 2.307077\n",
            "Train Epoch: 0 [6400/50000 (13%)]\tLoss: 1.584533\n",
            "Train Epoch: 0 [12800/50000 (26%)]\tLoss: 1.646685\n",
            "Train Epoch: 0 [19200/50000 (38%)]\tLoss: 1.410353\n",
            "Train Epoch: 0 [25600/50000 (51%)]\tLoss: 1.351616\n",
            "Train Epoch: 0 [32000/50000 (64%)]\tLoss: 1.184898\n",
            "Train Epoch: 0 [38400/50000 (77%)]\tLoss: 1.080835\n",
            "Train Epoch: 0 [44800/50000 (90%)]\tLoss: 0.908827\n",
            "Training set: Average loss: 0.0210\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.322823\n",
            "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 0.182651\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.073019\n",
            "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.106862\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.077112\n",
            "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.067159\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.059397\n",
            "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.104103\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.045406\n",
            "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.016395\n",
            "Training set: Average loss: 0.0022\n",
            "Train Epoch: 0 [0/50000 (0%)]\tLoss: 3.399140\n",
            "Train Epoch: 0 [6400/50000 (13%)]\tLoss: 2.180219\n",
            "Train Epoch: 0 [12800/50000 (26%)]\tLoss: 1.921016\n",
            "Train Epoch: 0 [19200/50000 (38%)]\tLoss: 2.032104\n",
            "Train Epoch: 0 [25600/50000 (51%)]\tLoss: 1.984804\n",
            "Train Epoch: 0 [32000/50000 (64%)]\tLoss: 1.784350\n",
            "Train Epoch: 0 [38400/50000 (77%)]\tLoss: 1.795895\n",
            "Train Epoch: 0 [44800/50000 (90%)]\tLoss: 1.827307\n",
            "Training set: Average loss: 0.0310\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 0.181427\n",
            "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 0.096525\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.075726\n",
            "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.144935\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.100269\n",
            "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.147332\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.046272\n",
            "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.055620\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.014372\n",
            "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.037455\n",
            "Training set: Average loss: 0.0016\n",
            "Train Epoch: 0 [0/50000 (0%)]\tLoss: 1.818942\n",
            "Train Epoch: 0 [6400/50000 (13%)]\tLoss: 1.957651\n",
            "Train Epoch: 0 [12800/50000 (26%)]\tLoss: 1.773716\n",
            "Train Epoch: 0 [19200/50000 (38%)]\tLoss: 1.800449\n",
            "Train Epoch: 0 [25600/50000 (51%)]\tLoss: 1.947541\n",
            "Train Epoch: 0 [32000/50000 (64%)]\tLoss: 1.673361\n",
            "Train Epoch: 0 [38400/50000 (77%)]\tLoss: 1.892196\n",
            "Train Epoch: 0 [44800/50000 (90%)]\tLoss: 1.692762\n",
            "Training set: Average loss: 0.0287\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 0.042336\n",
            "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 0.015494\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.037394\n",
            "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.033876\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.051958\n",
            "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.023965\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.043448\n",
            "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.068856\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.034575\n",
            "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.046778\n",
            "Training set: Average loss: 0.0010\n",
            "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.962024\n",
            "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 1.011618\n",
            "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 1.180910\n",
            "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 0.843258\n",
            "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.168355\n",
            "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 0.916201\n",
            "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 0.591323\n",
            "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 0.816353\n",
            "Training set: Average loss: 0.0152\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.000052\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.053202\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.002064\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.033798\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.001301\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.000496\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.021328\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.000965\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.003498\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.022495\n",
            "Training set: Average loss: 0.0004\n",
            "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.875016\n",
            "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 1.572548\n",
            "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 1.702807\n",
            "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 1.430526\n",
            "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.776764\n",
            "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 1.542911\n",
            "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 1.469650\n",
            "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 1.561235\n",
            "Training set: Average loss: 0.0265\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.163094\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.144072\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.024224\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.074209\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.286321\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.022837\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.011935\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.093239\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.026257\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.058251\n",
            "Training set: Average loss: 0.0007\n",
            "Train Epoch: 1 [0/50000 (0%)]\tLoss: 1.637126\n",
            "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 1.585325\n",
            "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 1.522144\n",
            "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 1.408426\n",
            "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.409928\n",
            "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 1.478893\n",
            "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 1.633677\n",
            "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 1.434757\n",
            "Training set: Average loss: 0.0245\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.053855\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.001125\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.089594\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.004145\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.011359\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.000616\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.021949\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.038121\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.088576\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.058357\n",
            "Training set: Average loss: 0.0004\n",
            "Train Epoch: 2 [0/50000 (0%)]\tLoss: 2.863765\n",
            "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 0.722250\n",
            "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 0.641595\n",
            "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 0.727527\n",
            "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 0.491180\n",
            "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 0.740385\n",
            "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 0.678469\n",
            "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 0.718718\n",
            "Training set: Average loss: 0.0119\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.030099\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.001704\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.001060\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.002682\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.000059\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.002867\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.001497\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.000107\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.009082\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.000165\n",
            "Training set: Average loss: 0.0002\n",
            "Train Epoch: 2 [0/50000 (0%)]\tLoss: 2.690663\n",
            "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 1.498316\n",
            "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 1.360555\n",
            "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 1.695682\n",
            "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.494268\n",
            "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 1.407321\n",
            "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 1.487268\n",
            "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 1.346723\n",
            "Training set: Average loss: 0.0239\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.017140\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.016783\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.026028\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.026268\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.015999\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.001834\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.003556\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.068315\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.002136\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.009663\n",
            "Training set: Average loss: 0.0004\n",
            "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.542710\n",
            "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 1.308244\n",
            "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 1.383280\n",
            "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 1.590045\n",
            "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.235381\n",
            "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 1.261428\n",
            "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 1.324039\n",
            "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 1.617644\n",
            "Training set: Average loss: 0.0218\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.016094\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.001718\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.004831\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.002771\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.001848\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.007208\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.001137\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.006357\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.007641\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.002368\n",
            "Training set: Average loss: 0.0002\n",
            "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.626728\n",
            "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 1.000517\n",
            "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 0.626313\n",
            "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 0.536742\n",
            "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 0.678502\n",
            "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 0.738076\n",
            "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 0.606531\n",
            "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 0.592379\n",
            "Training set: Average loss: 0.0093\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.006461\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.018506\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.000249\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.004926\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.070820\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.000850\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.133861\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.000243\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.000647\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.000011\n",
            "Training set: Average loss: 0.0001\n",
            "Train Epoch: 3 [0/50000 (0%)]\tLoss: 2.682350\n",
            "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 1.350985\n",
            "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 1.296748\n",
            "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 1.280184\n",
            "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 1.295685\n",
            "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 1.311247\n",
            "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 1.537387\n",
            "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 1.165152\n",
            "Training set: Average loss: 0.0214\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.013807\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.012073\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.004014\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.000873\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.004093\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.000215\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.001202\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.000727\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.000519\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.009048\n",
            "Training set: Average loss: 0.0003\n",
            "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.201053\n",
            "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 1.110297\n",
            "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 1.262987\n",
            "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 1.258906\n",
            "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 0.953352\n",
            "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 1.261621\n",
            "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 1.033481\n",
            "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 1.253815\n",
            "Training set: Average loss: 0.0190\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.038463\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.000217\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.000269\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.001207\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.005880\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.000974\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.023666\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.002628\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.000180\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.009725\n",
            "Training set: Average loss: 0.0001\n",
            "Train Epoch: 4 [0/50000 (0%)]\tLoss: 2.307070\n",
            "Train Epoch: 4 [6400/50000 (13%)]\tLoss: 0.403992\n",
            "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 0.418292\n",
            "Train Epoch: 4 [19200/50000 (38%)]\tLoss: 0.302857\n",
            "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 0.312345\n",
            "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 0.638515\n",
            "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 0.627312\n",
            "Train Epoch: 4 [44800/50000 (90%)]\tLoss: 0.430484\n",
            "Training set: Average loss: 0.0073\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.000578\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.000400\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.000107\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.000372\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.003485\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.000502\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.000595\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.000428\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.000000\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.000003\n",
            "Training set: Average loss: 0.0001\n",
            "Train Epoch: 4 [0/50000 (0%)]\tLoss: 2.274726\n",
            "Train Epoch: 4 [6400/50000 (13%)]\tLoss: 1.142829\n",
            "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 1.262468\n",
            "Train Epoch: 4 [19200/50000 (38%)]\tLoss: 1.103061\n",
            "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 1.186021\n",
            "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 1.088677\n",
            "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 1.195182\n",
            "Train Epoch: 4 [44800/50000 (90%)]\tLoss: 0.859645\n",
            "Training set: Average loss: 0.0191\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.031681\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.011409\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.000345\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.010650\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.010379\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.003870\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.066737\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.005860\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.001132\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.035030\n",
            "Training set: Average loss: 0.0002\n",
            "Train Epoch: 4 [0/50000 (0%)]\tLoss: 0.871939\n",
            "Train Epoch: 4 [6400/50000 (13%)]\tLoss: 1.046476\n",
            "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 1.095766\n",
            "Train Epoch: 4 [19200/50000 (38%)]\tLoss: 1.018048\n",
            "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 1.078415\n",
            "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 0.847636\n",
            "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 1.058589\n",
            "Train Epoch: 4 [44800/50000 (90%)]\tLoss: 1.009693\n",
            "Training set: Average loss: 0.0166\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.006108\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.006851\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.006604\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.000197\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.000160\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.000105\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.006119\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.009201\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.146654\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.003590\n",
            "Training set: Average loss: 0.0001\n",
            "Train Epoch: 5 [0/50000 (0%)]\tLoss: 1.540520\n",
            "Train Epoch: 5 [6400/50000 (13%)]\tLoss: 0.311286\n",
            "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 0.325931\n",
            "Train Epoch: 5 [19200/50000 (38%)]\tLoss: 0.172077\n",
            "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 0.508616\n",
            "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 0.336380\n",
            "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 0.508627\n",
            "Train Epoch: 5 [44800/50000 (90%)]\tLoss: 0.323287\n",
            "Training set: Average loss: 0.0055\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.002389\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.011288\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.000002\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.264503\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.001107\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.000000\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.000020\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.000009\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.013770\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.069624\n",
            "Training set: Average loss: 0.0001\n",
            "Train Epoch: 5 [0/50000 (0%)]\tLoss: 3.233258\n",
            "Train Epoch: 5 [6400/50000 (13%)]\tLoss: 1.055829\n",
            "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 1.192502\n",
            "Train Epoch: 5 [19200/50000 (38%)]\tLoss: 0.948618\n",
            "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 1.182203\n",
            "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 1.096714\n",
            "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 1.053653\n",
            "Train Epoch: 5 [44800/50000 (90%)]\tLoss: 0.960039\n",
            "Training set: Average loss: 0.0169\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.013763\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.000166\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.003586\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.003704\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.000605\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.000246\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.000141\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.000171\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.000535\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.000053\n",
            "Training set: Average loss: 0.0002\n",
            "Train Epoch: 5 [0/50000 (0%)]\tLoss: 0.805631\n",
            "Train Epoch: 5 [6400/50000 (13%)]\tLoss: 0.862216\n",
            "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 0.779670\n",
            "Train Epoch: 5 [19200/50000 (38%)]\tLoss: 0.826268\n",
            "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 0.976566\n",
            "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 0.823690\n",
            "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 0.678302\n",
            "Train Epoch: 5 [44800/50000 (90%)]\tLoss: 0.803675\n",
            "Training set: Average loss: 0.0143\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.006657\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.003237\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.000578\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.001308\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.002002\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.001140\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.000081\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.000059\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.000453\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.092193\n",
            "Training set: Average loss: 0.0001\n",
            "Train Epoch: 6 [0/50000 (0%)]\tLoss: 1.608984\n",
            "Train Epoch: 6 [6400/50000 (13%)]\tLoss: 0.220631\n",
            "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 0.211070\n",
            "Train Epoch: 6 [19200/50000 (38%)]\tLoss: 0.282844\n",
            "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 0.261520\n",
            "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 0.181343\n",
            "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 0.281021\n",
            "Train Epoch: 6 [44800/50000 (90%)]\tLoss: 0.388299\n",
            "Training set: Average loss: 0.0042\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.000022\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.000000\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.000001\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.000001\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.000000\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.000004\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.000012\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.000035\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.000008\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.000239\n",
            "Training set: Average loss: 0.0001\n",
            "Train Epoch: 6 [0/50000 (0%)]\tLoss: 2.152149\n",
            "Train Epoch: 6 [6400/50000 (13%)]\tLoss: 1.342120\n",
            "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 0.899169\n",
            "Train Epoch: 6 [19200/50000 (38%)]\tLoss: 0.934395\n",
            "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 0.900334\n",
            "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 0.913947\n",
            "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 0.831328\n",
            "Train Epoch: 6 [44800/50000 (90%)]\tLoss: 0.956050\n",
            "Training set: Average loss: 0.0148\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.002737\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.000101\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.000710\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.000074\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.017608\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.000026\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.000611\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.000010\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.000003\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.006887\n",
            "Training set: Average loss: 0.0001\n",
            "Train Epoch: 6 [0/50000 (0%)]\tLoss: 1.064587\n",
            "Train Epoch: 6 [6400/50000 (13%)]\tLoss: 0.816660\n",
            "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 0.825850\n",
            "Train Epoch: 6 [19200/50000 (38%)]\tLoss: 0.824566\n",
            "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 0.949629\n",
            "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 0.919066\n",
            "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 0.941551\n",
            "Train Epoch: 6 [44800/50000 (90%)]\tLoss: 0.844627\n",
            "Training set: Average loss: 0.0125\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.000836\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.039235\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.010707\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.006463\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.000030\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.001506\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.000084\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.000167\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.000414\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.014088\n",
            "Training set: Average loss: 0.0001\n",
            "Train Epoch: 7 [0/50000 (0%)]\tLoss: 1.480335\n",
            "Train Epoch: 7 [6400/50000 (13%)]\tLoss: 0.206398\n",
            "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 0.214590\n",
            "Train Epoch: 7 [19200/50000 (38%)]\tLoss: 0.262444\n",
            "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 0.120730\n",
            "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 0.111144\n",
            "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 0.110459\n",
            "Train Epoch: 7 [44800/50000 (90%)]\tLoss: 0.207032\n",
            "Training set: Average loss: 0.0034\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.000834\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.000000\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.000114\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.000440\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.000000\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.000151\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.006942\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.000001\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.000000\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.009074\n",
            "Training set: Average loss: 0.0001\n",
            "Train Epoch: 7 [0/50000 (0%)]\tLoss: 2.205181\n",
            "Train Epoch: 7 [6400/50000 (13%)]\tLoss: 0.926305\n",
            "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 0.927492\n",
            "Train Epoch: 7 [19200/50000 (38%)]\tLoss: 0.820800\n",
            "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 0.921389\n",
            "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 0.692187\n",
            "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 0.744745\n",
            "Train Epoch: 7 [44800/50000 (90%)]\tLoss: 0.691084\n",
            "Training set: Average loss: 0.0139\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.002154\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.002857\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.000049\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.000294\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.003243\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.000004\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.000009\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.000261\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.001596\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.028480\n",
            "Training set: Average loss: 0.0001\n",
            "Train Epoch: 7 [0/50000 (0%)]\tLoss: 0.636628\n",
            "Train Epoch: 7 [6400/50000 (13%)]\tLoss: 0.847102\n",
            "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 0.879710\n",
            "Train Epoch: 7 [19200/50000 (38%)]\tLoss: 0.672690\n",
            "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 0.780725\n",
            "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 0.627418\n",
            "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 0.641068\n",
            "Train Epoch: 7 [44800/50000 (90%)]\tLoss: 0.967375\n",
            "Training set: Average loss: 0.0114\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.000890\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.000238\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.005529\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.000129\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.000736\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.000894\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.001993\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.000486\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.060147\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.000067\n",
            "Training set: Average loss: 0.0001\n",
            "Train Epoch: 8 [0/50000 (0%)]\tLoss: 1.739606\n",
            "Train Epoch: 8 [6400/50000 (13%)]\tLoss: 0.127317\n",
            "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 0.117891\n",
            "Train Epoch: 8 [19200/50000 (38%)]\tLoss: 0.234041\n",
            "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 0.136671\n",
            "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 0.091851\n",
            "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 0.261184\n",
            "Train Epoch: 8 [44800/50000 (90%)]\tLoss: 0.133752\n",
            "Training set: Average loss: 0.0029\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.000000\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.000091\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.000018\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.000000\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.000001\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.000000\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.000227\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.067730\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.000000\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.000000\n",
            "Training set: Average loss: 0.0001\n",
            "Train Epoch: 8 [0/50000 (0%)]\tLoss: 2.960561\n",
            "Train Epoch: 8 [6400/50000 (13%)]\tLoss: 0.667232\n",
            "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 0.545913\n",
            "Train Epoch: 8 [19200/50000 (38%)]\tLoss: 0.808185\n",
            "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 0.741960\n",
            "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 0.561041\n",
            "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 0.546644\n",
            "Train Epoch: 8 [44800/50000 (90%)]\tLoss: 0.587266\n",
            "Training set: Average loss: 0.0117\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.009238\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.000364\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.031517\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.000004\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.001367\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.004336\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.002601\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.000118\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.004180\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.000586\n",
            "Training set: Average loss: 0.0001\n",
            "Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.895636\n",
            "Train Epoch: 8 [6400/50000 (13%)]\tLoss: 0.730475\n",
            "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 0.517692\n",
            "Train Epoch: 8 [19200/50000 (38%)]\tLoss: 0.623370\n",
            "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 0.540625\n",
            "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 0.622467\n",
            "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 0.494235\n",
            "Train Epoch: 8 [44800/50000 (90%)]\tLoss: 0.466206\n",
            "Training set: Average loss: 0.0100\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.000009\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.000221\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.000003\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.000011\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.000293\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.000013\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.000119\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.000068\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.051374\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.002133\n",
            "Training set: Average loss: 0.0001\n",
            "Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.997152\n",
            "Train Epoch: 9 [6400/50000 (13%)]\tLoss: 0.129827\n",
            "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 0.110248\n",
            "Train Epoch: 9 [19200/50000 (38%)]\tLoss: 0.201160\n",
            "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 0.186335\n",
            "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 0.100076\n",
            "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 0.120568\n",
            "Train Epoch: 9 [44800/50000 (90%)]\tLoss: 0.083725\n",
            "Training set: Average loss: 0.0027\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.000088\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.000362\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.000058\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.000002\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.035307\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.000000\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.021350\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.000001\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.000000\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.000000\n",
            "Training set: Average loss: 0.0001\n",
            "Train Epoch: 9 [0/50000 (0%)]\tLoss: 1.701592\n",
            "Train Epoch: 9 [6400/50000 (13%)]\tLoss: 0.778227\n",
            "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 0.617037\n",
            "Train Epoch: 9 [19200/50000 (38%)]\tLoss: 0.561178\n",
            "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 0.673921\n",
            "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 0.620723\n",
            "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 0.540563\n",
            "Train Epoch: 9 [44800/50000 (90%)]\tLoss: 0.717012\n",
            "Training set: Average loss: 0.0109\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.000164\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.000135\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.010751\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.000338\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.000035\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.000006\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.000223\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.000028\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.000015\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.002832\n",
            "Training set: Average loss: 0.0001\n",
            "Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.592062\n",
            "Train Epoch: 9 [6400/50000 (13%)]\tLoss: 0.662395\n",
            "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 0.755105\n",
            "Train Epoch: 9 [19200/50000 (38%)]\tLoss: 0.508290\n",
            "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 0.519017\n",
            "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 0.736119\n",
            "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 0.466792\n",
            "Train Epoch: 9 [44800/50000 (90%)]\tLoss: 0.434796\n",
            "Training set: Average loss: 0.0091\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.001454\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.000026\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.001558\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.000764\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.000281\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.000002\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.000042\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.000044\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.000004\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.000405\n",
            "Training set: Average loss: 0.0000\n",
            "\n",
            "Test set: Average loss: 2.4223, Accuracy: 5490/10000 (55%)\n",
            "\n",
            "\n",
            "Test set: Average loss: 0.0851, Accuracy: 9903/10000 (99%)\n",
            "\n",
            "\n",
            "Test set (adversarial): Average loss: 2.4519, Accuracy: 4457/10000 (45%)\n",
            "\n",
            "\n",
            "Test set (adversarial): Average loss: 0.1177, Accuracy: 9815/10000 (98%)\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Invalid attack method or missing parameters for PGD",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-e2c03c353e1d>\u001b[0m in \u001b[0;36m<cell line: 41>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# Test on PGD adversarial examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mtest_adversarial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_cifar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcifar_test_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpgd_attack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0mtest_adversarial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_mnist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnist_test_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpgd_attack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-88-2d65e1424dbe>\u001b[0m in \u001b[0;36mtest_adversarial\u001b[0;34m(model, device, test_loader, attack, epsilon, alpha, iters)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0madversarial_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpgd_attack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid attack method or missing parameters for PGD\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;31m# Evaluate on adversarial examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid attack method or missing parameters for PGD"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizing the Results"
      ],
      "metadata": {
        "id": "1uAcAHaSWZYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_results(images, adv_images, adv_images_pgd):\n",
        "    # Implement visualization of original, FGSM, and PGD images\n"
      ],
      "metadata": {
        "id": "PBEhEhuSWalj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}