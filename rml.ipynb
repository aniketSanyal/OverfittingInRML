{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aniketSanyal/OverfittingInRML/blob/main/rml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtSuGqoBLSBe"
      },
      "source": [
        "### Step 1: Setup Environment and Load Datasets\n",
        "\n",
        "1. **Import Libraries**: We'll import PyTorch, torchvision, and other necessary libraries.\n",
        "2. **Load Datasets**: Load MNIST and CIFAR10 datasets using torchvision.\n",
        "3. **Data Loaders**: Create data loaders for both datasets for easy batch processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzXGjNPgLSBh",
        "outputId": "0da6e7f1-2f70-4976-92b8-eedef0bf89fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Device configuration - GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# MNIST dataset\n",
        "mnist_train = torchvision.datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
        "mnist_test = torchvision.datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor())\n",
        "mnist_train_loader = DataLoader(dataset=mnist_train, batch_size=64, shuffle=True)\n",
        "mnist_test_loader = DataLoader(dataset=mnist_test, batch_size=64, shuffle=False)\n",
        "\n",
        "# CIFAR10 dataset\n",
        "cifar_train = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
        "cifar_test = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transforms.ToTensor())\n",
        "cifar_train_loader = DataLoader(dataset=cifar_train, batch_size=64, shuffle=True)\n",
        "cifar_test_loader = DataLoader(dataset=cifar_test, batch_size=64, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZS2HfPz8LSBi"
      },
      "source": [
        "### Step 2: Model Definition\n",
        "\n",
        "We'll define simple CNN architectures suitable for each dataset. MNIST images are grayscale and smaller, while CIFAR10 images are color and larger.\n",
        "\n",
        "#### MNIST CNN Model:\n",
        "- Simple architecture with a couple of convolutional layers.\n",
        "\n",
        "#### CIFAR10 CNN Model:\n",
        "- A bit more complex due to the nature of the dataset (color images)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "PafvVh37LSBi"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# CNN for MNIST\n",
        "class MNIST_CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNIST_CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, padding=2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, padding=2)\n",
        "        self.fc1 = nn.Linear(7*7*64, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
        "        x = x.view(x.size(0), -1) # Flatten\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# CNN for CIFAR10\n",
        "class CIFAR10_CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CIFAR10_CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=5, padding=2)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=5, padding=2)\n",
        "        self.fc1 = nn.Linear(8*8*128, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
        "        x = x.view(x.size(0), -1) # Flatten\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvsMeJqDLSBi"
      },
      "source": [
        "### Step 3: FGSM Function\n",
        "The FGSM method creates adversarial examples by adding a small perturbation to the original image in the direction of the gradient of the loss with respect to the input image.\n",
        "\n",
        "### Step 4: PGD Function\n",
        "PGD is a more powerful attack compared to FGSM. It applies the perturbation iteratively and projects the perturbed image back into the allowed range after each step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "tKwfDjtULSBj"
      },
      "outputs": [],
      "source": [
        "def fgsm_attack(image, epsilon, data_grad):\n",
        "    perturbed_image = image + epsilon * data_grad.sign()\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "    return perturbed_image\n",
        "\n",
        "def pgd_attack(model, image, label, epsilon, alpha, iters, device):\n",
        "    perturbation = torch.zeros_like(image).to(device)\n",
        "    perturbation.requires_grad = True\n",
        "\n",
        "    for _ in range(iters):\n",
        "        outputs = model(image + perturbation)\n",
        "        loss = F.cross_entropy(outputs, label)\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        perturbation.data = perturbation.data + alpha * perturbation.grad.data.sign()\n",
        "        perturbation.data = torch.clamp(perturbation.data, -epsilon, epsilon)\n",
        "\n",
        "    return image + perturbation.detach()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ff131KuILSBj"
      },
      "source": [
        "### Step 5: Training Loop with Adversarial Training\n",
        "\n",
        "We'll:\n",
        "1. Load pretrained models or train simple models for MNIST and CIFAR10.\n",
        "2. Select a few sample images from both datasets.\n",
        "3. Apply FGSM and PGD attacks on these samples.\n",
        "4. Visualize the results to see the effect of the attacks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iU3YdPOZLSBj",
        "outputId": "74cbfcd5-27ab-4025-f14b-f94b856b1115"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.317297\n",
            "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 1.953113\n",
            "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 1.904429\n",
            "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 1.848151\n",
            "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.657304\n",
            "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 1.747589\n",
            "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 1.893233\n",
            "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 1.699799\n",
            "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.861703\n",
            "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 1.482302\n",
            "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 1.649215\n",
            "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 1.480755\n",
            "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.493898\n",
            "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 1.501360\n",
            "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 1.443392\n",
            "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 1.518942\n",
            "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.351961\n",
            "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 1.581195\n",
            "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 1.591314\n",
            "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 1.426708\n",
            "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 1.388884\n",
            "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 1.381161\n",
            "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 1.544917\n",
            "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 1.470423\n",
            "Train Epoch: 4 [0/50000 (0%)]\tLoss: 1.381696\n",
            "Train Epoch: 4 [6400/50000 (13%)]\tLoss: 1.329850\n",
            "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 1.147733\n",
            "Train Epoch: 4 [19200/50000 (38%)]\tLoss: 1.316090\n",
            "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 1.117495\n",
            "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 1.542087\n",
            "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 1.419930\n",
            "Train Epoch: 4 [44800/50000 (90%)]\tLoss: 1.382160\n",
            "Train Epoch: 5 [0/50000 (0%)]\tLoss: 1.359034\n",
            "Train Epoch: 5 [6400/50000 (13%)]\tLoss: 1.439642\n",
            "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 1.225346\n",
            "Train Epoch: 5 [19200/50000 (38%)]\tLoss: 1.261069\n",
            "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 1.368457\n",
            "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 1.619372\n",
            "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 1.143676\n",
            "Train Epoch: 5 [44800/50000 (90%)]\tLoss: 1.199709\n",
            "Train Epoch: 6 [0/50000 (0%)]\tLoss: 1.207219\n",
            "Train Epoch: 6 [6400/50000 (13%)]\tLoss: 1.310945\n",
            "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 1.344327\n",
            "Train Epoch: 6 [19200/50000 (38%)]\tLoss: 1.257447\n",
            "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 1.260887\n",
            "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 1.435632\n",
            "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 1.370794\n",
            "Train Epoch: 6 [44800/50000 (90%)]\tLoss: 1.062704\n",
            "Train Epoch: 7 [0/50000 (0%)]\tLoss: 1.199000\n",
            "Train Epoch: 7 [6400/50000 (13%)]\tLoss: 1.097109\n",
            "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 1.137393\n",
            "Train Epoch: 7 [19200/50000 (38%)]\tLoss: 1.369659\n",
            "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 1.201150\n",
            "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 1.169998\n",
            "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 1.023066\n",
            "Train Epoch: 7 [44800/50000 (90%)]\tLoss: 1.227135\n",
            "Train Epoch: 8 [0/50000 (0%)]\tLoss: 1.140429\n",
            "Train Epoch: 8 [6400/50000 (13%)]\tLoss: 1.248602\n",
            "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 1.073513\n",
            "Train Epoch: 8 [19200/50000 (38%)]\tLoss: 1.157781\n",
            "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 1.282161\n",
            "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 1.129919\n",
            "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 1.157038\n",
            "Train Epoch: 8 [44800/50000 (90%)]\tLoss: 1.093065\n",
            "Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.980817\n",
            "Train Epoch: 9 [6400/50000 (13%)]\tLoss: 0.968495\n",
            "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 0.881178\n",
            "Train Epoch: 9 [19200/50000 (38%)]\tLoss: 1.069884\n",
            "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 1.051230\n",
            "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 1.137223\n",
            "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 1.207385\n",
            "Train Epoch: 9 [44800/50000 (90%)]\tLoss: 1.104607\n",
            "Train Epoch: 10 [0/50000 (0%)]\tLoss: 0.912272\n",
            "Train Epoch: 10 [6400/50000 (13%)]\tLoss: 0.921708\n",
            "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 0.961393\n",
            "Train Epoch: 10 [19200/50000 (38%)]\tLoss: 1.054428\n",
            "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 0.838733\n",
            "Train Epoch: 10 [32000/50000 (64%)]\tLoss: 0.927681\n",
            "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 1.181026\n",
            "Train Epoch: 10 [44800/50000 (90%)]\tLoss: 1.100707\n"
          ]
        }
      ],
      "source": [
        "def train(model, device, train_loader, optimizer, epoch, attack=None, epsilon=0.01):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        if attack is not None:\n",
        "            data.requires_grad = True\n",
        "            output = model(data)\n",
        "            loss = F.cross_entropy(output, target)\n",
        "            model.zero_grad()\n",
        "            loss.backward()\n",
        "            data_grad = data.grad.data\n",
        "            data = attack(model, data, target, epsilon, 0.01, 40, device) if attack == pgd_attack else fgsm_attack(data, epsilon, data_grad)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}\")\n",
        "\n",
        "# Example usage\n",
        "model = CIFAR10_CNN().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(1, 11):\n",
        "    train(model, device, cifar_train_loader, optimizer, epoch, attack=fgsm_attack, epsilon=0.01)\n",
        "    # Optionally, test your model here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Result"
      ],
      "metadata": {
        "id": "sEO3m-9gRx0u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize(image, title):\n",
        "    npimg = image.numpy()\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "# Take a sample for visualization\n",
        "dataiter = iter(cifar_test_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# FGSM\n",
        "images.requires_grad = True\n",
        "output = model_cifar(images.to(device))\n",
        "loss = F.cross_entropy(output, labels.to(device))\n",
        "model_cifar.zero_grad()\n",
        "loss.backward()\n",
        "\n",
        "perturbed_data = fgsm_attack(images, 0.05, images.grad)\n",
        "visualize(torchvision.utils.make_grid(perturbed_data.cpu()), \"FGSM Attack on CIFAR10\")\n",
        "\n",
        "# PGD\n",
        "perturbed_data_pgd = pgd_attack(model_cifar, images.to(device), labels.to(device), 0.05, 0.01, 40, device)\n",
        "visualize(torchvision.utils.make_grid(perturbed_data_pgd.cpu()), \"PGD Attack on CIFAR10\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Hw8ZdKqzR1W1",
        "outputId": "6f939837-d30f-4814-ee50-0beac78d476b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model_cifar' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-b72a1bdb8f1c>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# FGSM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_cifar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mmodel_cifar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_cifar' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}